{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CONFIG] Instalações e pacotes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema (os, makedirs, glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Básicos (numpy, math, display, locale, time, random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install jupyter\n",
    "\n",
    "\n",
    "# !python -m pip install IPython\n",
    "from IPython.display import display\n",
    "\n",
    "import math\n",
    "\n",
    "# !python -m pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "import locale\n",
    "# locale.setlocale(locale.LC_ALL, \"pt_BR.UTF-8\")  # Use \"\" for auto, or force e.g. to \"en_US.UTF-8\"\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# # !python -m pip install random\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e análise de dados (Excel, Pandas, Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install findspark\n",
    "\n",
    "# !python -m pip install openpyxl\n",
    "# !python -m pip install xlsxwriter\n",
    "# !python -m pip install xlrd\n",
    "# import openpyxl\n",
    "# import xlsxwriter\n",
    "\n",
    "# !python -m pip install pandas\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drive (para ler e escrever arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARA A LEITURA DOS DADOS EM PLANILHA DE SHEETS\n",
    "# # https://stackoverflow.com/questions/71686960/typeerror-credentials-need-to-be-from-either-oauth2client-or-from-google-auth\n",
    "# from google.colab import drive\n",
    "# from google.colab import auth\n",
    "# # !pip install gspread\n",
    "# import gspread\n",
    "# from google.auth import default\n",
    "# creds, _ = default()\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gc = gspread.authorize(creds)\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização (matplotlib, seaborn, plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n",
    "\n",
    "# !python -m pip install seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# !python -m pip install plotly\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# from plotly.subplots import make_subplots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automação (selenium, schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install selenium\n",
    "# !python -m pip install schedule\n",
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import schedule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install scikit-learn\n",
    "!python -m pip install -U imbalanced-learn\n",
    "!python -m pip install kneed\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterização (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install scikit-learn\n",
    "!python -m pip install -U imbalanced-learn\n",
    "!python -m pip install kneed\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, silhouette_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão computacional (OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install opencv-python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séries temporais (statsmodels, Prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install statsmodels\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "!python -m pip install prophet\n",
    "from prophet import Prophet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neurais (tensorflow, keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finanças (yfinance, mplfinance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/yfinance/\n",
    "# https://github.com/ranaroussi/yfinance/wiki/Ticker\n",
    "\n",
    "!python -m pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "!python -m pip install mplfinance\n",
    "import mplfinance as mpf\n",
    "\n",
    "# # Em R\n",
    "# # https://cran.r-project.org/web/packages/BatchGetSymbols/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de dados em sites e APIs (Beautiful Soup e requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# !python -m pip install requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresão (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura de arquivos com ID no Drive (_le_arquivos_drive_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_arquivos_drive(id_arquivo):\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "    !python -m pip install PyDrive# &> /dev/null\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    # id_arquivo = \"1sgkZW8mQCGdG_4DicIXFTCn3d-RBoRIk\" # Altere o token dos dados aqui\n",
    "\n",
    "    download = drive.CreateFile({'id': id_arquivo})\n",
    "\n",
    "    download.GetContentFile('file.csv')\n",
    "    dados  = pd.read_csv(\"file.csv\")\n",
    "\n",
    "    return dados\n",
    "    # dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura de arquivos em uma pasta local (_empilha_arquivos_pasta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empilha_arquivos_pasta(\n",
    "    caminho_pasta,\n",
    "    formato, \n",
    "    sep = \",\",\n",
    "    imprimir_nomes_arquivos = True, \n",
    "    adicionar_arquivo_base = True,\n",
    "    imprimir_check = True,\n",
    "    remover_duplicatas = False,\n",
    "    ):\n",
    "    \n",
    "    bd = pd.DataFrame()\n",
    "    check = 0\n",
    "    arquivos_nao_lidos = []\n",
    "\n",
    "    for filename in os.listdir(caminho_pasta):\n",
    "        if (filename.endswith(\".\" + formato.lower())) | (formato == \"\"):\n",
    "\n",
    "            if imprimir_nomes_arquivos == True:\n",
    "                print(\"Lendo arquivo \" + filename)\n",
    "\n",
    "            try:\n",
    "                if formato.lower() == \"csv\":\n",
    "                    try:\n",
    "                        try:\n",
    "                            novoArquivo = pd.read_csv(caminho_pasta + \"\\\\\" + filename, sep = sep, encoding = \"utf-8\", engine = \"python\")\n",
    "                        except:\n",
    "                            novoArquivo = pd.read_csv(caminho_pasta + \"\\\\\" + filename, encoding = \"utf-8\", engine = \"python\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            novoArquivo = pd.read_csv(caminho_pasta + \"\\\\\" + filename, sep = sep, encoding='iso-8859-1', engine = \"python\")\n",
    "                        except:\n",
    "                            novoArquivo = pd.read_csv(caminho_pasta + \"\\\\\" + filename, encoding='iso-8859-1', engine = \"python\")\n",
    "                            \n",
    "                elif formato.lower() == \"xlsx\":\n",
    "                    novoArquivo = pd.read_excel(caminho_pasta)\n",
    "\n",
    "                if adicionar_arquivo_base == True:\n",
    "                    novoArquivo[\"Arquivo\"] = filename\n",
    "\n",
    "                check = check + len(novoArquivo)\n",
    "                bd = pd.concat([bd, novoArquivo])\n",
    "                print(\"Leitura do arquivo \" + filename + \" concluída\")\n",
    "            \n",
    "            except:\n",
    "                arquivos_nao_lidos.append(filename)\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if imprimir_check == True:\n",
    "        if (len(bd) == check):\n",
    "            check = \"ok\"\n",
    "        else:\n",
    "            check = \"nok\"\n",
    "        print(\"Check: \" + check + \", \" + str(len(bd))) \n",
    "\n",
    "    if remover_duplicatas == True:\n",
    "        bd = bd.drop_duplicates()\n",
    "\n",
    "    return [bd, arquivos_nao_lidos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lê arquivo do Google Sheets em CSV (_convert_google_sheet_url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_google_sheet_url(url):\n",
    "    # Regular expression to match and capture the necessary part of the URL\n",
    "    pattern = r'https://docs\\.google\\.com/spreadsheets/d/([a-zA-Z0-9-_]+)(/edit#gid=(\\d+)|/edit.*)?'\n",
    "\n",
    "    # Replace function to construct the new URL for CSV export\n",
    "    # If gid is present in the URL, it includes it in the export URL, otherwise, it's omitted\n",
    "    replacement = lambda m: f'https://docs.google.com/spreadsheets/d/{m.group(1)}/export?' + (f'gid={m.group(3)}&' if m.group(3) else '') + 'format=csv'\n",
    "\n",
    "    # Replace using regex\n",
    "    new_url = re.sub(pattern, replacement, url)\n",
    "\n",
    "    return new_url\n",
    "\n",
    "# caminho = \"https://docs.google.com/spreadsheets/d/1FO7R8HkhqqHfVgup5-52DTDKT_roiVpBARNTlgxchCo/edit#gid\"\n",
    "# base = pd.read_csv(convert_google_sheet_url(caminho))\n",
    "# base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amostra da base (_amostra_da_base_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amostra_da_base(bd, qtd_por_grupo, taxa_de_conversao, random_state = 1):\n",
    "    quantidade = min(int(round(qtd_por_grupo/taxa_de_conversao, 0)), len(bd))\n",
    "    \n",
    "    if random_state == False:\n",
    "        return bd.sample(n = quantidade)\n",
    "    else:\n",
    "        return bd.sample(n = quantidade, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória básica de todos os campos da base - MUITO ÚTIL (_analise_exploratoria_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_exploratoria(\n",
    "    bd,\n",
    "    imprime_todas_colunas = False,\n",
    "    imprime_info_colunas = True,\n",
    "    imprime_colunas_vazias = False,\n",
    "    imprime_colunas_completas = False,\n",
    "    imprime_colunas_parciais = False,\n",
    "    remove_da_base = True,\n",
    "    retorna_parciais = False,\n",
    "    detalhar_colunas_parciais = True,\n",
    "    colunas_ignoradas = []\n",
    "    ):\n",
    "\n",
    "    # COMEÇANDO PELAS COLUNAS DISPONÍVEIS E INFO\n",
    "    if imprime_todas_colunas == True:\n",
    "        display(bd.columns)\n",
    "    \n",
    "    if imprime_info_colunas == True:\n",
    "        for i in range(int(np.ceil(len(bd.columns)/20))):\n",
    "            display(bd.iloc[:, (i*20):min((i+1)*20, len(bd.columns))].info())\n",
    "\n",
    "    # DETALHAMENTO DE QUAIS COLUNAS SÃO NA OU PARCIAIS\n",
    "    if retorna_parciais == True:\n",
    "        [bd_semNA, colunas_parciais] = elimina_colunas_NA(\n",
    "            bd,\n",
    "            imprime_colunas_vazias = imprime_colunas_vazias,\n",
    "            imprime_colunas_completas = imprime_colunas_completas,\n",
    "            imprime_colunas_parciais = imprime_colunas_parciais,\n",
    "            remove_da_base = remove_da_base,\n",
    "            retorna_parciais = retorna_parciais\n",
    "        )\n",
    "\n",
    "        if detalhar_colunas_parciais == True:\n",
    "            for coluna in colunas_parciais:\n",
    "                print(\"# \" + coluna + \": \" + str(len(colunas_parciais[colunas_parciais[coluna].isna()])))\n",
    "    else:\n",
    "        colunas_parciais = []\n",
    "\n",
    "        bd_semNA = elimina_colunas_NA(\n",
    "            bd,\n",
    "            imprime_colunas_vazias = imprime_colunas_vazias,\n",
    "            imprime_colunas_completas = imprime_colunas_completas,\n",
    "            imprime_colunas_parciais = imprime_colunas_parciais,\n",
    "            remove_da_base = remove_da_base,\n",
    "            retorna_parciais = retorna_parciais\n",
    "        )\n",
    "\n",
    "    [campos_com_erro, colunas_agrupadas] = agrupamento_cada_coluna(\n",
    "        bd.reset_index(), \n",
    "        coluna_completa = bd_semNA.drop(colunas_parciais, axis = 1).reset_index().columns[0],\n",
    "        colunas_ignoradas = colunas_ignoradas\n",
    "    )\n",
    "    \n",
    "    if retorna_parciais == True:\n",
    "        return [bd_semNA, colunas_parciais, colunas_agrupadas, campos_com_erro]\n",
    "    else:\n",
    "        return [bd_semNA, colunas_agrupadas, campos_com_erro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamentos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimina colunas NA (_elimina_colunas_NA_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimina_colunas_NA(\n",
    "    base,\n",
    "    imprime_colunas_vazias = False,\n",
    "    imprime_colunas_completas = False,\n",
    "    imprime_colunas_parciais = False,\n",
    "    remove_da_base = True,\n",
    "    retorna_parciais = False\n",
    "    ):\n",
    "\n",
    "    tamanho_da_base = len(base)\n",
    "\n",
    "    colunas_vazias = []\n",
    "    colunas_completas = []\n",
    "    colunas_parciais = []\n",
    "\n",
    "    for coluna in base.columns:\n",
    "        tamanho_da_coluna = len(base[base[coluna].isna()])\n",
    "        if tamanho_da_coluna == tamanho_da_base:\n",
    "            # print(coluna)\n",
    "            colunas_vazias.append(coluna)\n",
    "        elif tamanho_da_coluna == 0:\n",
    "            colunas_completas.append(coluna)\n",
    "        else:\n",
    "            colunas_parciais.append(coluna)\n",
    "\n",
    "    if imprime_colunas_vazias == True:\n",
    "        if len(colunas_vazias) == 0:\n",
    "            print(\"Não há colunas NA\")\n",
    "        else:\n",
    "            print(\"Colunas vazias: \" + str(colunas_vazias))\n",
    "            \n",
    "    if imprime_colunas_completas == True:\n",
    "        if len(colunas_completas) == 0:\n",
    "            print(\"Não há colunas completas\")\n",
    "        else:\n",
    "            print(\"Colunas completas: \" + str(colunas_completas))\n",
    "    \n",
    "    if imprime_colunas_parciais == True:\n",
    "        if len(colunas_parciais) == 0:\n",
    "            print(\"Não há colunas parciais\")\n",
    "        else:\n",
    "            print(\"Colunas parciais: \" + str(colunas_parciais))\n",
    "\n",
    "    if remove_da_base == True:\n",
    "        base = base.drop(colunas_vazias, axis = 1)\n",
    "    \n",
    "    if retorna_parciais == True:\n",
    "        return [base, colunas_parciais]\n",
    "    else:\n",
    "        return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adiciona campo agrupado (_adiciona_campo_agrupado_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adiciona_campo_agrupado(\n",
    "    bd_limpa, bd_unificada, \n",
    "    campos_identificadores, \n",
    "    novo_campo, \n",
    "    imprime_campos = True,\n",
    "    imprime_checks = True\n",
    "    ):\n",
    "    \n",
    "    novo_campos_identificadores = campos_identificadores.copy()\n",
    "    novo_campos_identificadores.append(novo_campo)\n",
    "    if imprime_campos == True:\n",
    "        print(str(novo_campos_identificadores))\n",
    "\n",
    "    bd_limpa_com_campos = bd_limpa[novo_campos_identificadores] \\\n",
    "        .groupby(novo_campos_identificadores).first().reset_index()\n",
    "\n",
    "    bd_limpa_com_campos = bd_limpa_com_campos.groupby(campos_identificadores).last()\n",
    "\n",
    "    if novo_campo in bd_unificada.columns:\n",
    "        bd_unificada_novo = bd_unificada.drop(novo_campo, axis = 1).join(bd_limpa_com_campos, how = \"outer\")\n",
    "    else:\n",
    "        bd_unificada_novo = bd_unificada.join(bd_limpa_com_campos, how = \"outer\")\n",
    "\n",
    "    if imprime_checks == True:\n",
    "        print(novo_campo + \" vazios: \" + str(len(bd_unificada_novo[bd_unificada_novo[novo_campo].isna()])))\n",
    "        print(novo_campo + \" não vazios: \" + str(len(bd_unificada_novo[~bd_unificada_novo[novo_campo].isna()])))\n",
    "\n",
    "    return bd_unificada_novo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completa dígitos, por exemplo padronizar chaves, CPF, etc (_completa_digitos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completa_digitos(texto, qtd):\n",
    "    quantidade_zeros = qtd - len(texto)\n",
    "\n",
    "    contador = quantidade_zeros\n",
    "    while contador > 0:\n",
    "        texto = \"0\" + texto\n",
    "        contador = contador - 1\n",
    "\n",
    "    # print(len(texto))\n",
    "\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolida primeiro campo não NA entre duas opções (_consolida_primeiro_campo_existente_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolida_primeiro_campo_existente(campoA, campoB):\n",
    "    try:\n",
    "        import numpy as np\n",
    "\n",
    "        if np.isnan(campoA):\n",
    "            return campoB\n",
    "        else:\n",
    "            return campoA\n",
    "    except:\n",
    "        if pd.isnull(campoA):\n",
    "            return campoB\n",
    "        else:\n",
    "            return campoA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupar cada coluna (_agrupamento_cada_coluna_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupamento_cada_coluna(\n",
    "    bd, \n",
    "    coluna_completa, \n",
    "    colunas_ignoradas = [], \n",
    "    ascending = False,\n",
    "    imprime_tabelas = True,\n",
    "    ):\n",
    "    \n",
    "    from IPython.display import display\n",
    "\n",
    "    campos_com_erro = []\n",
    "    dict_campos = {}\n",
    "\n",
    "    colunas = bd.columns.drop(coluna_completa)\n",
    "\n",
    "    if len(colunas_ignoradas) > 0:\n",
    "        colunas = colunas.drop(colunas_ignoradas)\n",
    "    \n",
    "    for coluna in colunas:\n",
    "        try: \n",
    "            temp_coluna = bd.fillna(\"(vazio)\").groupby(coluna).count()[[coluna_completa]].rename(columns = {coluna_completa: \"Quantidade\"}).sort_values(\"Quantidade\", ascending = ascending)\n",
    "\n",
    "            if ascending == False:\n",
    "                temp_coluna[\"%\"] = temp_coluna[\"Quantidade\"]/temp_coluna[\"Quantidade\"].sum()\n",
    "                temp_coluna[\"% acumulado\"] = temp_coluna[\"%\"].cumsum()\n",
    "            \n",
    "            if imprime_tabelas == True:\n",
    "                display(temp_coluna)\n",
    "                \n",
    "            dict_campos[coluna] = temp_coluna\n",
    "            limpa(temp_coluna)\n",
    "        \n",
    "        except:\n",
    "            campos_com_erro.append(coluna)\n",
    "            #print(\"Campo \" + coluna + \" deu erro =/\")\n",
    "    \n",
    "    return [campos_com_erro, dict_campos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplos de repetições na BD (_exemplos_repeticoes_na_bd_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exemplos_repeticoes_na_bd(\n",
    "    bd_filtro_linhas, \n",
    "    campos_filtro_colunas, \n",
    "    coluna_completa, \n",
    "    ascending = False\n",
    "    ):\n",
    "    \n",
    "    print(\"A tabela possui \" + str(len(bd_filtro_linhas[campos_filtro_colunas])) + \" linhas na base vezes na base\")\n",
    "    \n",
    "    bd_agrupada = bd_filtro_linhas[campos_filtro_colunas+[coluna_completa]] \\\n",
    "        .groupby(campos_filtro_colunas).count() \\\n",
    "        .rename(columns = {coluna_completa: \"Quantidade\"}) \\\n",
    "        .sort_values(\"Quantidade\", ascending = ascending)\n",
    "\n",
    "    return bd_agrupada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De Para basicão com loc (_de_para_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_para(tabela_de_para, coluna_de):\n",
    "    try:\n",
    "        return tabela_de_para.loc[coluna_de][0]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenação de colunas (parâmetros), usando uma lista como referência (_concat_parametros_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_parametros(\n",
    "  lista_parametros,\n",
    "  tabela,\n",
    "):\n",
    "\n",
    "  str_parametros = \"\"\n",
    "  for parametro in lista_parametros:\n",
    "    if parametro == lista_parametros[-1]:\n",
    "      str_parametros = str_parametros + str(parametro)\n",
    "\n",
    "    else:\n",
    "      str_parametros = str(parametro) + \" - \" + str_parametros\n",
    "\n",
    "  tabela[str_parametros] = \"\"\n",
    "  for parametro in lista_parametros:\n",
    "    if parametro == lista_parametros[-1]:\n",
    "      tabela[str_parametros] = tabela[str_parametros] + tabela[parametro].astype(str)\n",
    "\n",
    "    else:\n",
    "      tabela[str_parametros] = tabela[parametro].astype(str) + \" - \" + tabela[str_parametros]\n",
    "      # str_parametros = str_parametros + parametro\n",
    "    \n",
    "\n",
    "  tabela_resultados\n",
    "\n",
    "  return (str_parametros, tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encaixa um determinado valor entre dois valores que são representados por listas de faixas mínimas e máximas (_encaixa_na_faixa_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encaixa_na_faixa(faixa_minima, faixa_maxima, valor, tipo = \"less-inclusive\"):\n",
    "    faixa_minima.sort()\n",
    "    faixa_maxima.sort()\n",
    "\n",
    "    tabela_personalizada = pd.DataFrame(index = faixa_minima, data = faixa_maxima) \\\n",
    "                                        .reset_index() \\\n",
    "                                        .rename(columns = {\"index\": \"Faixa mínima\", 0: \"Faixa máxima\"}).astype(float)\n",
    "\n",
    "    tabela_personalizada[\"Faixa\"] = tabela_personalizada[\"Faixa mínima\"].astype(str).str.split(\".\").str[0] + \\\n",
    "                                     \" a \" + \\\n",
    "                                     tabela_personalizada[\"Faixa máxima\"].astype(str).str.split(\".\").str[0]\n",
    "    \n",
    "    if tipo == \"more-inclusive\":\n",
    "        \n",
    "        for contador in range(len(tabela_personalizada)):\n",
    "            if (valor > tabela_personalizada.iloc[contador][\"Faixa mínima\"]) & (valor <= tabela_personalizada.iloc[contador][\"Faixa máxima\"]):\n",
    "                # display(tabela_personalizada.iloc[contador])\n",
    "                return tabela_personalizada.iloc[contador][\"Faixa\"]\n",
    "        \n",
    "        return \"Fora das faixas\"\n",
    "\n",
    "    if tipo == \"inclusive\":\n",
    "        \n",
    "        for contador in range(len(tabela_personalizada)):\n",
    "            if (valor >= tabela_personalizada.iloc[contador][\"Faixa mínima\"]) & (valor <= tabela_personalizada.iloc[contador][\"Faixa máxima\"]):\n",
    "                # display(tabela_personalizada.iloc[contador])\n",
    "                return tabela_personalizada.iloc[contador][\"Faixa\"]\n",
    "        \n",
    "        return \"Fora das faixas\"\n",
    "\n",
    "    # if tipo == \"exclusive\": \\\\ mutuamente exclusivo (não tem igual)\n",
    "\n",
    "    else:\n",
    "    # if tipo == \"less-inclusive\":\n",
    "\n",
    "        for contador in range(len(tabela_personalizada)):\n",
    "            if (valor >= tabela_personalizada.iloc[contador][\"Faixa mínima\"]) & (valor < tabela_personalizada.iloc[contador][\"Faixa máxima\"]):\n",
    "                # display(tabela_personalizada.iloc[contador])\n",
    "                return tabela_personalizada.iloc[contador][\"Faixa\"]\n",
    "        \n",
    "        return \"Fora das faixas\"\n",
    "\n",
    "\n",
    "# lista_idade_minima = [float(\"-inf\"), 17, 25, 31, 41, 51]\n",
    "# lista_idade_maxima = [16, 24, 30, 40, 50, float(\"inf\")]\n",
    "\n",
    "# encaixa_na_faixa(lista_idade_minima, lista_idade_maxima, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar para o Excel, já com uma tabelinha pronta para fazer Pivot Tables (_exporta_excel_com_tabela_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exporta_excel_com_tabela(\n",
    "        bd,\n",
    "        caminho_nome_arquivo\n",
    "        ):\n",
    "    # https://stackoverflow.com/questions/58326392/how-to-create-excel-table-with-pandas-to-excel\n",
    "    # import pandas as pd\n",
    "\n",
    "    # Create a Pandas dataframe from some data.\n",
    "    # data = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "    # df = pd.DataFrame({'Rank': data,\n",
    "                    # 'Country': data,\n",
    "                    # 'Population': data,\n",
    "                    # 'Data1': data,\n",
    "                    # 'Data2': data})\n",
    "\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(caminho_nome_arquivo, engine='xlsxwriter')\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object. Turn off the default\n",
    "    # header and index and skip one row to allow us to insert a user defined\n",
    "    # header.\n",
    "    bd.to_excel(writer, sheet_name='Sheet1', startrow=1, header=False, index=False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Get the dimensions of the dataframe.\n",
    "    (max_row, max_col) = bd.shape\n",
    "\n",
    "    # Create a list of column headers, to use in add_table().\n",
    "    column_settings = []\n",
    "    for header in bd.columns:\n",
    "        column_settings.append({'header': header})\n",
    "\n",
    "    # Add the table.\n",
    "    worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings})\n",
    "\n",
    "    # Make the columns wider for clarity.\n",
    "    worksheet.set_column(0, max_col - 1, 12)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "# exporta_excel_com_tabela(\n",
    "        # bd = dados_consolidado,\n",
    "        # caminho_nome_arquivo = caminho + \"Custo e Volume de Produção.xlsx\"\n",
    "        # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizações rápidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma padrão (_histograma_padrao_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn [3], line 3\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhistograma_padrao\u001b[39m(\n",
      "\u001b[0;32m      2\u001b[0m     dados_x,\n",
      "\u001b[1;32m----> 3\u001b[0m     titulo \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan,\n",
      "\u001b[0;32m      4\u001b[0m     dados_indice \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan,\n",
      "\u001b[0;32m      5\u001b[0m     tipo \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhist\u001b[39m\u001b[39m\"\u001b[39m,\n",
      "\u001b[0;32m      6\u001b[0m     grid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n",
      "\u001b[0;32m      7\u001b[0m     legend \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n",
      "\u001b[0;32m      8\u001b[0m     linha_media \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan,\n",
      "\u001b[0;32m      9\u001b[0m     qtd_bins \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n",
      "\u001b[0;32m     10\u001b[0m     espessura \u001b[39m=\u001b[39m \u001b[39m0.8\u001b[39m,\n",
      "\u001b[0;32m     11\u001b[0m     limite_x_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan, limite_x_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan,\n",
      "\u001b[0;32m     12\u001b[0m     limite_y_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan, limite_y_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan,\n",
      "\u001b[0;32m     13\u001b[0m     ):\n",
      "\u001b[0;32m     15\u001b[0m     plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m,\u001b[39m8\u001b[39m))\n",
      "\u001b[0;32m     17\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m(pd\u001b[39m.\u001b[39misnull(titulo)):\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def histograma_padrao(\n",
    "  dados_x,\n",
    "  titulo = np.nan,\n",
    "  dados_indice = np.nan,\n",
    "  tipo = \"hist\",\n",
    "  grid = False,\n",
    "  legend = True,\n",
    "  linha_media = np.nan,\n",
    "  qtd_bins = 10,\n",
    "  espessura = 0.8,\n",
    "  limite_x_min = np.nan, limite_x_max = np.nan,\n",
    "  limite_y_min = np.nan, limite_y_max = np.nan,\n",
    "  ):\n",
    "  \n",
    "  plt.figure(figsize = (20,8))\n",
    "\n",
    "  if not(pd.isnull(titulo)):\n",
    "      plt.title(titulo, fontsize = 16)\n",
    "\n",
    "  if tipo == \"hist\":\n",
    "      n, bins, edges = plt.hist(\n",
    "          dados_x,\n",
    "          bins = qtd_bins,\n",
    "          rwidth = espessura\n",
    "          )\n",
    "      plt.xticks(bins)\n",
    "      \n",
    "  elif tipo == \"bar\":\n",
    "      plt.bar(\n",
    "          dados_indice,\n",
    "          dados_x,\n",
    "          width = espessura\n",
    "          )\n",
    "\n",
    "  \n",
    "  \n",
    "  if not(math.isnan(linha_media)):\n",
    "      plt.axvline(x=linha_media, color = \"black\", label='Média')\n",
    "  \n",
    "  if legend == True:\n",
    "      plt.legend()\n",
    "  \n",
    "  plt.grid(grid)\n",
    "\n",
    "  if (not(math.isnan(limite_x_max))) & (not(math.isnan(limite_x_min))):\n",
    "      # print(limite_x_min)\n",
    "      # print(~math.isnan(limite_x_max))\n",
    "      plt.xlim(limite_x_min, limite_x_max)\n",
    "  \n",
    "  if (not(math.isnan(limite_y_max))) & (not(math.isnan(limite_y_min))):\n",
    "      plt.ylim(limite_y_min, limite_y_max)\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico no Matplotlib com rótulos (_grafico_com_rotulos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_com_rotulos(\n",
    "    dados, coluna_x, coluna_y, \n",
    "    tipo_grafico = \"bar\", titulo_grafico = \"\", tamanho_grafico = (20, 8),\n",
    "    fig = None, ax = None, \n",
    "    tamanho_fonte = 12, grossura_barra = 1,\n",
    "    cor_x = \"b\", rotacao_x = 0, \n",
    "    formato_y = \"{:.2f}\", rotacao_y = 0, limite_min_y = None, limite_max_y = None,\n",
    "    xytext_label_y = (0,10),\n",
    "  ):\n",
    "  \n",
    "  # dados_plot = dados_cliente[dados_cliente[\"% Faturamento Acumulado\"] < 0.40]\n",
    "\n",
    "  if fig is None:\n",
    "    fig = plt.figure(figsize = tamanho_grafico)\n",
    "  \n",
    "  plt.clf()\n",
    "  plt.rcParams.update({'font.size': tamanho_fonte})\n",
    "\n",
    "\n",
    "  ys = dados[coluna_y]\n",
    "  xs = np.arange(len(dados[coluna_x]))\n",
    "\n",
    "  if (tipo_grafico == \"bar\") | (tipo_grafico == \"line\"):\n",
    "    if (tipo_grafico == \"bar\"):\n",
    "      plt.bar(\n",
    "          x = xs,\n",
    "          height = ys,\n",
    "          width = grossura_barra,\n",
    "          label = coluna_y,\n",
    "      )\n",
    "    elif (tipo_grafico == \"line\"):\n",
    "      plt.plot(\n",
    "        xs,\n",
    "        ys,\n",
    "        cor_x + \"o-\",\n",
    "        label = coluna_y,\n",
    "      )\n",
    "\n",
    "    # display(cor_x + \"o-\")\n",
    "\n",
    "\n",
    "    ax1 = plt.gca()\n",
    "    if (limite_min_y is not None) & (limite_max_y is not None):\n",
    "      ax1.set_ylim([min(dados[coluna_y])*limite_min_y, max(dados[coluna_y])*limite_max_y])\n",
    "\n",
    "    ax1.set_ylabel(coluna_y, color = cor_x)\n",
    "    ax1.set_xlabel(coluna_x)\n",
    "\n",
    "    for x,y in zip(xs,ys):\n",
    "        label = formato_y.format(y)\n",
    "\n",
    "        plt.annotate(label, # this is the text\n",
    "                    (x,y), # these are the coordinates to position the label\n",
    "                    textcoords=\"offset points\", # how to position the text\n",
    "                    xytext = xytext_label_y, # distance from text to points (x,y)\n",
    "                    ha='center', # horizontal alignment can be left, right or center\n",
    "                    color = cor_x,\n",
    "                    rotation = rotacao_y)\n",
    "\n",
    "\n",
    "    ax1.xaxis.set_tick_params(rotation = rotacao_x)\n",
    "\n",
    "    # fig.legend()\n",
    "    plt.xticks(xs, dados[coluna_x])\n",
    "\n",
    "  elif tipo_grafico == \"barh\":\n",
    "    plt.barh(\n",
    "        y = xs,\n",
    "        width = ys,\n",
    "        height = grossura_barra,\n",
    "        # label = coluna_y,\n",
    "    )\n",
    "    ax1 = plt.gca()\n",
    "    ax1.set_yticks(xs, dados[coluna_x])\n",
    "\n",
    "    ax1.set_ylabel(coluna_x)\n",
    "    ax1.set_xlabel(coluna_y, color = cor_x)\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    if (limite_min_y is not None) & (limite_max_y is not None):\n",
    "      ax1.set_xlim([min(dados[coluna_y])*limite_min_y, max(dados[coluna_y])*limite_max_y])\n",
    "\n",
    "    for x,y in zip(xs,ys):\n",
    "      label = formato_y.format(y)\n",
    "\n",
    "      plt.annotate(label, # this is the text\n",
    "                (y, x), # these are the coordinates to position the label\n",
    "                textcoords=\"offset points\", # how to position the text\n",
    "                xytext = (xytext_label_y[1], xytext_label_y[0]), # distance from text to points (x,y)\n",
    "                ha='center', # horizontal alignment can be left, right or center\n",
    "                color = cor_x,\n",
    "                rotation = rotacao_y)\n",
    "\n",
    "  plt.title(titulo_grafico)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch padronizado (_treina_modelo_grid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treina_modelo_grid(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  modelo,\n",
    "  param_grid,\n",
    "  cv = 10,\n",
    "  scoring = \"neg_mean_absolute_error\",\n",
    "  tipo = \"grid\",\n",
    "  random_state_seed = 1082141,\n",
    "  n_iter = 50\n",
    "):\n",
    "  from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "  \n",
    "  if tipo == \"grid\":\n",
    "      grid = GridSearchCV(\n",
    "          modelo, \n",
    "          param_grid, \n",
    "          cv = cv, \n",
    "          scoring = scoring, \n",
    "          return_train_score = True,\n",
    "      )\n",
    "\n",
    "  elif tipo == \"randomized\":\n",
    "      # print(\"Busca randomizada em \" + str(n_iter) + \" combinações de parâmetros.\")\n",
    "      grid = RandomizedSearchCV(\n",
    "          modelo, \n",
    "          param_grid, \n",
    "          cv = cv, \n",
    "          scoring = scoring, \n",
    "          return_train_score = True,\n",
    "          random_state = random_state_seed,\n",
    "          n_iter = n_iter,\n",
    "      )\n",
    "\n",
    "  grid.fit(x_train, y_train)\n",
    "\n",
    "  return grid\n",
    "\n",
    "### Definimos range de hiperparâmetros\n",
    "# n_neighbors_range = range(10, 20)\n",
    "# metric_range = [\"cityblock\", \"cosine\", \"euclidean\", \"haversine\", \"l1\", \"l2\", \"manhattan\", \"nan_euclidean\", \"minkowski\"]\n",
    "# algorithm_range = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "# param_grid = dict(algorithm = algorithm_range)\n",
    "# # display(param_grid) \n",
    "\n",
    "# grid_melhor_algorithm = treina_modelo_grid(\n",
    "#     dados_treino_X,\n",
    "#     dados_treino_y,\n",
    "#     KNeighborsClassifier(n_neighbors = 12, metric = \"euclidean\"),\n",
    "#     param_grid,\n",
    "#     cv = 5,\n",
    "#     scoring = \"accuracy\",\n",
    "#     tipo = \"grid\",\n",
    "#     random_state_seed = numero_aleatorio,\n",
    "#     # n_iter = 50\n",
    "# )\n",
    "\n",
    "# # print(grid.best_score_)\n",
    "# # grid.best_estimator_\n",
    "# tabela_resultados = pd.concat([\n",
    "#   pd.json_normalize(pd.DataFrame(grid_melhor_algorithm.cv_results_)[\"params\"]),\n",
    "#   pd.DataFrame(grid_melhor_algorithm.cv_results_)[[\"rank_test_score\", \"mean_test_score\"]]\n",
    "# ], axis = 1).set_index(\"rank_test_score\").sort_index()\n",
    "\n",
    "\n",
    "# plt.figure(figsize = (15,8))\n",
    "# display(tabela_resultados)\n",
    "# plt.bar(x = tabela_resultados[\"algorithm\"], height = tabela_resultados[\"mean_test_score\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finanças, Day Trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão linear com pontos de uma ação (_criar_regressao_bd_acao_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_regressao_bd_acao(\n",
    "  bd_acao,\n",
    "  coluna = \"Close\",\n",
    "  print_variaveis = False,\n",
    "  plot_grafico = False,\n",
    "  tamanho_figsize = (10,5),\n",
    "  rotacao = 45,\n",
    "  titulo = \"Pontos no fechamento da ação\",\n",
    "  var_pular_final_de_semana_feriados = False,\n",
    "):\n",
    "  # bd_acao\n",
    "\n",
    "  bd_acao_coluna = bd_acao.reset_index()[[bd_acao.index.name, coluna]]\n",
    "  # bd_acao_coluna\n",
    "\n",
    "  # from sklearn.linear_model import LinearRegression\n",
    "\n",
    "  X = bd_acao_coluna.reset_index()[\"index\"].array.reshape(-1, 1)\n",
    "  y = bd_acao_coluna.loc[:, coluna].array.reshape(-1, 1)\n",
    "\n",
    "  modelo_linear = LinearRegression()\n",
    "  modelo_linear.fit(X, y)\n",
    "\n",
    "  bd_acao_coluna.loc[:, \"Regressão\"] = modelo_linear.predict(X)\n",
    "  # bd_acao_fim\n",
    "\n",
    "  desvio_padrao = bd_acao_coluna[coluna].std()\n",
    "  media = bd_acao_coluna[coluna].mean()\n",
    "  alfa = modelo_linear.coef_[0][0]\n",
    "  valor_fechamento = bd_acao_coluna.sort_index(ascending = False).iloc[0][coluna]\n",
    "\n",
    "  # margem = 0.005\n",
    "  margem = desvio_padrao/media\n",
    "\n",
    "  if print_variaveis == True:\n",
    "    display(\"Média: \" + \"{:.4f}\".format(media))\n",
    "    display(\"Desvio padrão: \" + \"{:.4f}\".format(desvio_padrao))\n",
    "    display(\"Desvio padrão (%): \" + \"{:.4f}\".format(margem))\n",
    "    display(\"Inclinação da reta (alfa, coeficiente angular): \" + \"{:.4f}\".format(alfa))\n",
    "    display(\"Valor de fechamento (R$): \" + \"{:.2f}\".format(valor_fechamento))\n",
    "\n",
    "\n",
    "  if plot_grafico == True:\n",
    "    plt.figure(figsize = tamanho_figsize)\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    if var_pular_final_de_semana_feriados == True:\n",
    "      ax.xaxis.set_major_locator(ticker.LinearLocator(len(bd_acao_coluna)))\n",
    "      # ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "      # ax.xaxis.set_major_formatter(mdates.DateFormatter(fmt = \"%d/%m/%y\"))\n",
    "\n",
    "      plt.xticks(rotation = rotacao)\n",
    "\n",
    "      plt.scatter(x = bd_acao_coluna[bd_acao.index.name].dt.strftime(\"%d/%m/%y\").astype(str), y = coluna, data = bd_acao_coluna, edgecolors='black', facecolors='none')\n",
    "\n",
    "      plt.plot(bd_acao_coluna[bd_acao.index.name].dt.strftime(\"%d/%m/%y\").astype(str), bd_acao_coluna[\"Regressão\"]-desvio_padrao, color = \"blue\", linestyle='dashed')\n",
    "      plt.plot(bd_acao_coluna[bd_acao.index.name].dt.strftime(\"%d/%m/%y\").astype(str), bd_acao_coluna[\"Regressão\"], color='green')\n",
    "      plt.plot(bd_acao_coluna[bd_acao.index.name].dt.strftime(\"%d/%m/%y\").astype(str), bd_acao_coluna[\"Regressão\"]+desvio_padrao, color = \"blue\", linestyle='dashed')\n",
    "\n",
    "      # ax.xaxis.set_major_formatter(mdates.DateFormatter(fmt = \"%d/%m/%y\"))\n",
    "      # ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "\n",
    "    else:\n",
    "      ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "\n",
    "      plt.xticks(bd_acao_coluna[bd_acao.index.name], rotation = rotacao)\n",
    "\n",
    "      plt.scatter(x = bd_acao_coluna[bd_acao.index.name], y = coluna, data = bd_acao_coluna, edgecolors='black', facecolors='none')\n",
    "\n",
    "      plt.plot(bd_acao_coluna[bd_acao.index.name], bd_acao_coluna[\"Regressão\"]-desvio_padrao, color = \"blue\", linestyle='dashed')\n",
    "      plt.plot(bd_acao_coluna[bd_acao.index.name], bd_acao_coluna[\"Regressão\"], color='green')\n",
    "      plt.plot(bd_acao_coluna[bd_acao.index.name], bd_acao_coluna[\"Regressão\"]+desvio_padrao, color = \"blue\", linestyle='dashed')\n",
    "\n",
    "\n",
    "    plt.title(titulo)\n",
    "    plt.show()\n",
    "\n",
    "  return [bd_acao_coluna, media, desvio_padrao, modelo_linear, valor_fechamento]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candle Plot (_candle_plot_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candle_plot(\n",
    "    dados,\n",
    "    volume = True,\n",
    "    mav = np.nan,\n",
    "    colors = [\"orange\", \"yellow\", \"blue\"],\n",
    "    titulo = \"\",\n",
    "    ):\n",
    "\n",
    "  # !python -m pip install plotly\n",
    "  from plotly.subplots import make_subplots\n",
    "  import plotly.graph_objects as go\n",
    "  \n",
    "  if volume == True:\n",
    "    fig = make_subplots(\n",
    "        rows = 2,\n",
    "        cols = 1,\n",
    "        shared_xaxes = True,\n",
    "        vertical_spacing = 0.1,\n",
    "        subplot_titles = (\"Candlesticks\", \"Volume transacionado\"),\n",
    "        row_width = [0.2, 0.7]\n",
    "    )\n",
    "  else:\n",
    "    fig = make_subplots(\n",
    "        rows = 1,\n",
    "        cols = 1,\n",
    "        shared_xaxes = True,\n",
    "        vertical_spacing = 0.1,\n",
    "        subplot_titles = (\"Candlesticks\"),\n",
    "        row_width = [0.2, 0.7]\n",
    "    )\n",
    "\n",
    "  fig.add_trace(go.Candlestick(x=dados.index,\n",
    "                      open = dados['Open'],\n",
    "                      high = dados['High'],\n",
    "                      low = dados['Low'],\n",
    "                      close = dados['Close']),\n",
    "                row = 1, col = 1)\n",
    "\n",
    "  if mav is not np.nan:\n",
    "    for i in range(len(mav)):\n",
    "      # print(i)\n",
    "      dados[\"Close \"+ str(mav[i]) +\" dias\"] = dados[\"Close\"].rolling(window=mav[i]).mean()\n",
    "      fig.add_trace(go.Scatter(x=dados.index,\n",
    "                          y = dados[\"Close \"+ str(mav[i]) +\" dias\"],\n",
    "                          mode = \"lines\",\n",
    "                          name = \"Média móvel fechamento \" + str(mav[i]) + \" dias\",\n",
    "                          marker=dict(color=colors[i])),\n",
    "                    row = 1, col = 1)\n",
    "\n",
    "  if volume == True:\n",
    "    fig.add_trace(go.Bar(x=dados.head(60).index,\n",
    "                        y = dados['Volume'],\n",
    "                        name = \"Volume\"),\n",
    "                  row = 2, col = 1)\n",
    "\n",
    "\n",
    "  fig.update_layout(\n",
    "      yaxis_title = \"Preço\",\n",
    "      xaxis_rangeslider_visible=False,\n",
    "      title=titulo,\n",
    "      )\n",
    "\n",
    "  fig.show()\n",
    "\n",
    "# candle_plot(\n",
    "#     dados = dados_candle_matp_media_movel.head(60),\n",
    "#     volume = True,\n",
    "#     mav = [7,14],\n",
    "#     # colors = [\"orange\", \"yellow\", \"blue\"],\n",
    "#     titulo = \"PETR4.SA\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plota candlesticks e acha martelos (_plota_candlestick_acha_martelos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_candlestick_acha_martelos(\n",
    "    acao,\n",
    "    periodo = \"21d\",\n",
    "    intervalo = \"1d\",\n",
    "    taxa_máxima_para_ser_martelo = 0.2,\n",
    "    display_tabela_martelo = True,\n",
    "    display_candlestick = True,\n",
    "\n",
    "  ):\n",
    "\n",
    "  bd_acao = yf.Ticker(acao).history(\n",
    "      period = periodo,\n",
    "      interval = intervalo\n",
    "  )\n",
    "  bd_acao[\"Amplitude Open-Close\"] = abs(bd_acao[\"Open\"] - bd_acao[\"Close\"])\n",
    "  bd_acao[\"Amplitude High-Low\"] = abs(bd_acao[\"High\"] - bd_acao[\"Low\"])\n",
    "\n",
    "  # taxa_máxima_para_ser_martelo = 0.2\n",
    "  bd_acao[\"Martelo?\"] = (bd_acao[\"Amplitude Open-Close\"] < taxa_máxima_para_ser_martelo * bd_acao[\"Amplitude High-Low\"])\n",
    "\n",
    "  lista_datas_martelo = bd_acao[bd_acao[\"Martelo?\"] == True].sort_index(ascending = False).index.to_pydatetime()\n",
    "  string_datas_martelo = \"\"\n",
    "  for data in lista_datas_martelo:\n",
    "    string_datas_martelo = data.strftime(\"%d/%m/%y\") + \", \" + string_datas_martelo\n",
    "\n",
    "  # string_datas_martelo[:-2]\n",
    "\n",
    "\n",
    "  if display_tabela_martelo == True:\n",
    "    display(bd_acao[bd_acao[\"Martelo?\"] == True])\n",
    "\n",
    "  if display_candlestick == True:\n",
    "    candle_plot(\n",
    "    bd_acao,\n",
    "    volume = True,\n",
    "    # mav = np.nan,\n",
    "    # colors = [\"orange\", \"yellow\", \"blue\"],\n",
    "    titulo = acao,\n",
    "    )\n",
    "\n",
    "  return [bd_acao, string_datas_martelo]\n",
    "\n",
    "[_, string_datas_martelo] = plota_candlestick_acha_martelos(\n",
    "    acao =  \"PETR3\" + \".SA\",\n",
    "    periodo = \"60d\",\n",
    "    intervalo = \"1d\",\n",
    "    taxa_máxima_para_ser_martelo = 0.2,\n",
    "    display_tabela_martelo = True,\n",
    "    display_candlestick = True,\n",
    "  );\n",
    "\n",
    "display(string_datas_martelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpa memória - NÃO FUNCIONA (_retrieve_name_, _limpa_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_name(var):\n",
    "    import inspect\n",
    "\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    \n",
    "    return [var_name for var_name, var_val in callers_local_vars if var_val is var][0]\n",
    "\n",
    "def limpa(ponteiro):\n",
    "    try:\n",
    "        del(ponteiro)\n",
    "        import gc\n",
    "        gc.collect()\n",
    "    except:\n",
    "        print(\"Não foi possível limpar \"+ retrieve_name(ponteiro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise exploratória"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação treino e teste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação/Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
